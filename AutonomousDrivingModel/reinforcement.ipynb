{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18c61206",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\TANMAY\\anaconda3\\envs\\carla-sim\\lib\\site-packages\\gymnasium\\spaces\\box.py:130: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  gym.logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 71   |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 28   |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 66           |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 62           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010846719 |\n",
      "|    clip_fraction        | 0.000684     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.26        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 138          |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00101     |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 278          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 61           |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 99           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013162374 |\n",
      "|    clip_fraction        | 0.00112      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.27        |\n",
      "|    explained_variance   | -3.58e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 138          |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.000914    |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 277          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 59           |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 136          |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020802887 |\n",
      "|    clip_fraction        | 0.00405      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.25        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 137          |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.00243     |\n",
      "|    std                  | 0.995        |\n",
      "|    value_loss           | 277          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 162         |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002414859 |\n",
      "|    clip_fraction        | 0.00483     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.2        |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 138         |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00209    |\n",
      "|    std                  | 0.971       |\n",
      "|    value_loss           | 276         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x1fa528b5848>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import numpy as np\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "class CarlaGymEnv(gym.Env):\n",
    "    def __init__(self):\n",
    "        super(CarlaGymEnv, self).__init__()\n",
    "        self.observation_space = spaces.Box(low=0, high=255, shape=(84, 84, 1), dtype=np.uint8)\n",
    "        self.action_space = spaces.Box(low=np.array([-1.0, -1.0, -1.0]), \n",
    "                                       high=np.array([1.0, 1.0, 1.0]), dtype=np.float32)\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        return np.zeros((84, 84, 1), dtype=np.uint8), {}\n",
    "\n",
    "    def step(self, action):\n",
    "        obs = np.zeros((84, 84, 1), dtype=np.uint8)\n",
    "        reward = 1.0\n",
    "        done = False\n",
    "        truncated = False\n",
    "        info = {}\n",
    "        return obs, reward, done, truncated, info\n",
    "\n",
    "    def render(self):\n",
    "        pass\n",
    "\n",
    "# Check env\n",
    "env = CarlaGymEnv()\n",
    "check_env(env, warn=True)\n",
    "\n",
    "# Wrap for SB3\n",
    "vec_env = DummyVecEnv([lambda: env])\n",
    "\n",
    "# Train model\n",
    "model = PPO(\"CnnPolicy\", vec_env, verbose=1)\n",
    "model.learn(total_timesteps=10000)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carla-sim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
